{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m9MNjr50i9Vf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        # [10 numericals] # x / y / type / code / weather / plane_model / airport_origin / airport_dest / month / day_week / x' / y'\n",
    "        self.samples = list()\n",
    "        self.ground_truths = list()\n",
    "        print(\"Reading LSTM data..\")\n",
    "        \n",
    "        with open(data_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        for i,row in enumerate(data):\n",
    "          self.samples.append(torch.tensor(row[\"sample\"]))\n",
    "          self.ground_truths.append(torch.tensor(row[\"labels\"], dtype=torch.float32))\n",
    "\n",
    "        # with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            # csv_reader = csv.reader(f)\n",
    "            # header = next(csv_reader)\n",
    "            # for line in tqdm(csv_reader):\n",
    "            #     # TODO make sure line is a list\n",
    "            #     self.samples.append(line[:-2]) #TODO check everything apart from last element\n",
    "            #     # TODO include ground truth separately\n",
    "            #     self.ground_truths.append(line[-1])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.ground_truths[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTKN-1EFizpX",
    "outputId": "5a6d3ce7-7569-4cb3-f21c-7d1dfacb8863"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'frechet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrechet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frechet_distance\n\u001b[1;32m      6\u001b[0m trajectory_p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m80.0644976552576\u001b[39m, \u001b[38;5;241m50.6552672944963\u001b[39m],\n\u001b[1;32m      7\u001b[0m                           [\u001b[38;5;241m71.4585771784186\u001b[39m, \u001b[38;5;241m63.2156178820878\u001b[39m],\n\u001b[1;32m      8\u001b[0m                           [\u001b[38;5;241m19.9234400875866\u001b[39m, \u001b[38;5;241m12.8415436018258\u001b[39m]])\n\u001b[1;32m     10\u001b[0m trajectory_q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m5.88378887623549\u001b[39m, \u001b[38;5;241m11.4293440245092\u001b[39m],\n\u001b[1;32m     11\u001b[0m                           [\u001b[38;5;241m84.2895035166293\u001b[39m, \u001b[38;5;241m67.4984930083156\u001b[39m],\n\u001b[1;32m     12\u001b[0m                           [\u001b[38;5;241m90.9000392071903\u001b[39m, \u001b[38;5;241m36.4088270813227\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m                           [\u001b[38;5;241m62.438058713451\u001b[39m, \u001b[38;5;241m44.4697478786111\u001b[39m],\n\u001b[1;32m     18\u001b[0m                           [\u001b[38;5;241m38.4228205773979\u001b[39m, \u001b[38;5;241m66.4192265830934\u001b[39m]])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'frechet'"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "\n",
    "import numpy as np\n",
    "from frechet import frechet_distance\n",
    "\n",
    "trajectory_p = np.array([[80.0644976552576, 50.6552672944963],\n",
    "                          [71.4585771784186, 63.2156178820878],\n",
    "                          [19.9234400875866, 12.8415436018258]])\n",
    "\n",
    "trajectory_q = np.array([[5.88378887623549, 11.4293440245092],\n",
    "                          [84.2895035166293, 67.4984930083156],\n",
    "                          [90.9000392071903, 36.4088270813227],\n",
    "                          [34.2789062298834, 0.568102905526757],\n",
    "                          [43.9584670122713, 75.5553565453738],\n",
    "                          [24.4398877490312, 30.7297872845083],\n",
    "                          [35.2576361969113, 39.8860249202698],\n",
    "                          [62.438058713451, 44.4697478786111],\n",
    "                          [38.4228205773979, 66.4192265830934]])\n",
    "\n",
    "print(type(trajectory_p))\n",
    "print(type(trajectory_q))\n",
    "print(type(trajectory_p[0][0]))\n",
    "print(type(trajectory_q[0][0]))\n",
    "score = frechet_distance(trajectory_p, trajectory_q)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "_G5im9KoIe1_"
   },
   "outputs": [],
   "source": [
    "# Interpolation\n",
    "\n",
    "def interpolate(inp, fi):\n",
    "    i, f = int(fi // 1), fi % 1  # Split floating-point index into whole & fractional parts.\n",
    "    j = i+1 if f > 0 else i  # Avoid index error.\n",
    "    return (1-f) * inp[i] + f * inp[j]\n",
    "\n",
    "# inp = [1, 3, 5, 7, 9]\n",
    "# new_len = 10\n",
    "\n",
    "# delta = (len(inp)-1) / (new_len-1)\n",
    "# outp = [interpolate(inp, i*delta) for i in range(new_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "_Jn3G6tUYRyg"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, input_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "      \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=self.hidden_dim, num_layers=1)\n",
    "        self.fc = nn.Linear(in_features=self.hidden_dim, out_features=2)\n",
    "        # [SeqLength, Batch, hidden_size]\n",
    "\n",
    "    def forward(self, x):\n",
    "        out,_ = self.lstm(x)\n",
    "        out_fc = self.fc(out)\n",
    "        # predictions = out[:, :, -1]\n",
    "        # TODO add interpolation\n",
    "        # predictions_interpolated = predictions\n",
    "        return out_fc#predictions_interpolated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIox2yjnjG64",
    "outputId": "4808cc0a-6860-4d60-ac02-4fb089fc74d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading LSTM data..\n",
      "Iteration: 100. Loss: 9898.75390625.\n",
      "Iteration: 200. Loss: 9899.8486328125.\n",
      "Iteration: 300. Loss: 9898.8115234375.\n",
      "Iteration: 400. Loss: 9898.880859375.\n",
      "Iteration: 500. Loss: 9899.3544921875.\n",
      "Iteration: 600. Loss: 9898.6611328125.\n",
      "Iteration: 700. Loss: 9898.6640625.\n",
      "Iteration: 800. Loss: 9899.9638671875.\n",
      "Iteration: 900. Loss: 9899.17578125.\n",
      "Iteration: 1000. Loss: 9899.244140625.\n",
      "Iteration: 1100. Loss: 9898.732421875.\n",
      "Iteration: 1200. Loss: 9899.228515625.\n",
      "Iteration: 1300. Loss: 9898.970703125.\n",
      "Iteration: 1400. Loss: 9898.6484375.\n",
      "Iteration: 1500. Loss: 9898.8125.\n",
      "Iteration: 1600. Loss: 9900.548828125.\n",
      "Iteration: 1700. Loss: 9899.15234375.\n",
      "Iteration: 1800. Loss: 9898.654296875.\n",
      "Iteration: 1900. Loss: 9898.6875.\n",
      "Iteration: 2000. Loss: 9898.640625.\n",
      "Iteration: 2100. Loss: 9898.73828125.\n",
      "Iteration: 2200. Loss: 9898.69921875.\n",
      "Iteration: 2300. Loss: 9898.68359375.\n",
      "Iteration: 2400. Loss: 9899.5791015625.\n",
      "Iteration: 2500. Loss: 9898.6533203125.\n",
      "Iteration: 2600. Loss: 9898.646484375.\n",
      "Iteration: 2700. Loss: 9899.21875.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "# dataset\n",
    "data_path = \"/Users/filipzarnecki/AiGames/data/prepared_data/data.json\"#\"/Users/filipzarnecki/AiGames/data/prepared_data/mock.csv\"\n",
    "trajectory_dataset = TrajectoryDataset(data_path)\n",
    "\n",
    "train_len = round(len(trajectory_dataset)*0.9)\n",
    "# print(train_len)\n",
    "val_len = len(trajectory_dataset) - train_len\n",
    "train, val = random_split(trajectory_dataset, [train_len, val_len], generator=torch.Generator().manual_seed(2022))\n",
    "\n",
    "\n",
    "# data loaders\n",
    "batch_size = 1\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(trajectory_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = DataLoader(dataset=train, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=val, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False)\n",
    "\n",
    "\n",
    "# vaiables\n",
    "input_size = 7\n",
    "hidden_dim = 50\n",
    "\n",
    "model = LSTMModel(hidden_dim, input_size)\n",
    "\n",
    "\n",
    "# check\n",
    "# print(model)\n",
    "# print(len(list(model.parameters())))\n",
    "# for i in range(len(list(model.parameters()))):\n",
    "#     print(list(model.parameters())[i].size())\n",
    "\n",
    "\n",
    "# loss\n",
    "# criterion = frechet_distance\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  #sgd\n",
    "\n",
    "\n",
    "# training\n",
    "# Number of steps to unroll\n",
    "# seq_dim = 28  \n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input_vectors, labels) in enumerate(train_loader):\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        # print(input_vectors.shape)\n",
    "        outputs = model(input_vectors)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        # print(outputs.shape)\n",
    "        # print(labels.shape)\n",
    "        # outputs = torch.squeeze(outputs).numpy().astype(dtype=\"float64\")\n",
    "        # labels = torch.squeeze(labels).numpy().astype(dtype=\"float64\")\n",
    "        # print(outputs.shape)\n",
    "        # print(labels.shape)\n",
    "        # loss = frechet_distance(outputs, labels)\n",
    "\n",
    "        # print(outputs.type())\n",
    "        # print(labels.type())\n",
    "        outputs = torch.nn.functional.interpolate(torch.unsqueeze(outputs, 1), size=labels.shape[1:])#\n",
    "        # print(outputs.type())\n",
    "        # print(labels.type())\n",
    "\n",
    "        loss = torch.cdist(outputs, labels)\n",
    "        loss = torch.sum(loss, (1,2,3))\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 100 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            frechet_distances = []\n",
    "            # Iterate through test dataset\n",
    "            for input_vectors, labels in val_loader:\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(input_vectors)\n",
    "\n",
    "                outputs = torch.nn.functional.interpolate(torch.unsqueeze(outputs, 1), size=labels.shape[1:])\n",
    "                # print(outputs.type())\n",
    "                # print(labels.type())\n",
    "\n",
    "                loss = torch.cdist(outputs, labels)\n",
    "                loss = torch.sum(loss, (1,2,3))\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJihfhIoZ2XF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
